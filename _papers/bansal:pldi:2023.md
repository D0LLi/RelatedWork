---
ENTRYTYPE: article
abstract: We introduce Mosaic, a sparse tensor algebra compiler that can bind tensor expressions to external functions of other tensor algebra libraries
  and compilers. Users can extend Mosaic by adding new functions and bind a sub-expression to a function using a scheduling API. Mosaic substitutes the
  bound sub-expressions with calls to the external functions and automatically generates the remaining code using a default code generator. As the generated
  code is fused by default, users can productively leverage both fusion and calls to specialized functions within the same compiler. We demonstrate the
  benefits of our dual approach by showing that calling hand-written CPU and specialized hardware functions can provide speedups of up to 206\texttimes  against
  fused code in some cases, while generating fused code can provide speedups of up to 3.57\texttimes  against code that calls external functions in other
  cases. Mosaic also offers a search system that can automatically map an expression to a set of registered external functions. Both the explicit binding
  and automatic search are verified by Mosaic. Additionally, the interface for adding new external functions is simple and general. Currently, 38 external
  functions have been added to Mosaic, with each addition averaging 20 lines of code.
added: 2023-07-02
address: New York, NY, USA
articleno: '122'
authors:
- Manya Bansal
- Olivia Hsu
- Kunle Olukotun
- Fredrik Kjolstad
doi: 10.1145/3591236
issue_date: June 2023
journal: Proc. ACM Program. Lang.
keywords: external functions, automated search, sparse tensor algebra, compilation
layout: paper
link: https://doi.org/10.1145/3591236
month: jun
number: PLDI
numpages: '26'
publisher: Association for Computing Machinery
read: false
readings: []
title: 'Mosaic: An interoperable compiler for tensor algebra'
url: https://doi.org/10.1145/3591236
volume: '7'
year: 2023
notes:
- machine learning
- tensor
- sparse model
- loop fusion
papers:
---

Tensor algebra compilers are important because we want to target
a very broad range of hardware (with new designs coming out all the time)
and to cope with many different combinations of sparse and dense
tensors (where each dimension of each operand can be dense or sparse).

The big contribution of this paper is that it can exploit both
vector instructions (like existing tensor algebra compilers)
and vector libraries (hand-written or generated by other tools).


{% include links.html %}
